{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqRlNjTRfcYSwlOh7/axCV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Adversarial Autoencoder\n"
      ],
      "metadata": {
        "id": "gRNvELiCAOzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "2DrR1zNCAMWb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed for reproducibility\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU6gnVdXDIEz",
        "outputId": "feb161c1-77f9-4acb-98f4-f88fcb0ab486"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x77fd5a6acf10>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder network\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim=768, latent_dim=256):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 512)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "\n",
        "        self.fc2 = nn.Linear(512, 384)\n",
        "        self.bn2 = nn.BatchNorm1d(384)\n",
        "\n",
        "        self.fc3 = nn.Linear(384, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.leaky_relu(self.bn1(self.fc1(x)), 0.2)\n",
        "        h = F.leaky_relu(self.bn2(self.fc2(h)), 0.2)\n",
        "        latent = self.fc3(h)\n",
        "        return latent"
      ],
      "metadata": {
        "id": "r3xaCbxsDNF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder network\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim=256, output_dim=768):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, 384)\n",
        "        self.bn1 = nn.BatchNorm1d(384)\n",
        "\n",
        "        self.fc2 = nn.Linear(384, 512)\n",
        "        self.bn2 = nn.BatchNorm1d(512)\n",
        "\n",
        "        self.fc3 = nn.Linear(512, output_dim)\n",
        "\n",
        "    def forward(self, z):\n",
        "        h = F.leaky_relu(self.bn1(self.fc1(z)), 0.2)\n",
        "        h = F.leaky_relu(self.bn2(self.fc2(h)), 0.2)\n",
        "        reconstructed = torch.sigmoid(self.fc3(h))\n",
        "        return reconstructed"
      ],
      "metadata": {
        "id": "-qOA_NnPDP7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, latent_dim=256):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, 256)\n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "\n",
        "        self.fc3 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, z):\n",
        "        h = F.leaky_relu(self.bn1(self.fc1(z)), 0.2)\n",
        "        h = F.leaky_relu(self.bn2(self.fc2(h)), 0.2)\n",
        "        logits = self.fc3(h)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "ocgdbGtsDaty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the full Adversarial Autoencoder\n",
        "class AdversarialAutoencoder:\n",
        "    def __init__(self, input_dim=768, latent_dim=256, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        self.input_dim = input_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.device = device\n",
        "\n",
        "        # Initialize networks\n",
        "        self.encoder = Encoder(input_dim, latent_dim).to(device)\n",
        "        self.decoder = Decoder(latent_dim, input_dim).to(device)\n",
        "        self.discriminator = Discriminator(latent_dim).to(device)\n",
        "\n",
        "        # Initialize optimizers\n",
        "        self.encoder_optimizer = optim.Adam(self.encoder.parameters(), lr=0.001)\n",
        "        self.decoder_optimizer = optim.Adam(self.decoder.parameters(), lr=0.001)\n",
        "        self.discriminator_optimizer = optim.Adam(self.discriminator.parameters(), lr=0.0001)\n",
        "\n",
        "        # Loss functions\n",
        "        self.reconstruction_loss = nn.MSELoss()\n",
        "        self.adversarial_loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def train_step(self, x_batch):\n",
        "        batch_size = x_batch.size(0)\n",
        "        x_batch = x_batch.to(self.device)\n",
        "\n",
        "        # Target tensors\n",
        "        real_target = torch.ones(batch_size, 1).to(self.device)\n",
        "        l = torch.zeros(batch_size, 1).to(self.device)\n",
        "\n",
        "        # Train Autoencoder\n",
        "        self.encoder_optimizer.zero_grad()\n",
        "        self.decoder_optimizer.zero_grad()\n",
        "\n",
        "        # Encode and decode the input\n",
        "        z = self.encoder(x_batch)\n",
        "        x_reconstructed = self.decoder(z)\n",
        "\n",
        "        # Compute reconstruction loss\n",
        "        recon_loss = self.reconstruction_loss(x_reconstructed, x_batch)\n",
        "\n",
        "        # Compute adversarial loss for the generator (encoder)\n",
        "        gen_loss = self.adversarial_loss(self.discriminator(z), real_target)\n",
        "\n",
        "        # Total autoencoder loss\n",
        "        ae_loss = recon_loss + gen_loss\n",
        "\n",
        "        # Backpropagate and update parameters\n",
        "        ae_loss.backward()\n",
        "        self.encoder_optimizer.step()\n",
        "        self.decoder_optimizer.step()\n",
        "\n",
        "        # Train Discriminator\n",
        "        self.discriminator_optimizer.zero_grad()\n",
        "\n",
        "        # Generate latent vectors from the prior distribution (Gaussian in this case)\n",
        "        z_prior = torch.randn(batch_size, self.latent_dim).to(self.device)\n",
        "\n",
        "        # Get encoded samples\n",
        "        z_encoded = self.encoder(x_batch).detach()  # Detach to avoid training the encoder again\n",
        "\n",
        "        # Compute discriminator loss\n",
        "        real_loss = self.adversarial_loss(self.discriminator(z_prior), real_target)\n",
        "        fake_loss = self.adversarial_loss(self.discriminator(z_encoded), fake_target)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        # Backpropagate and update parameters\n",
        "        d_loss.backward()\n",
        "        self.discriminator_optimizer.step()\n",
        "\n",
        "        return {\n",
        "            'reconstruction_loss': recon_loss.item(),\n",
        "            'generator_loss': gen_loss.item(),\n",
        "            'discriminator_loss': d_loss.item()\n",
        "        }\n",
        "\n",
        "    def train(self, data_loader, epochs=100):\n",
        "        self.encoder.train()\n",
        "        self.decoder.train()\n",
        "        self.discriminator.train()\n",
        "\n",
        "        training_history = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            epoch_losses = {'reconstruction_loss': 0, 'generator_loss': 0, 'discriminator_loss': 0}\n",
        "            batch_count = 0\n",
        "\n",
        "            for batch_idx, (x_batch, _) in enumerate(data_loader):\n",
        "                step_losses = self.train_step(x_batch)\n",
        "\n",
        "                for key in epoch_losses:\n",
        "                    epoch_losses[key] += step_losses[key]\n",
        "                batch_count += 1\n",
        "\n",
        "            # Calculate average losses for the epoch\n",
        "            for key in epoch_losses:\n",
        "                epoch_losses[key] /= batch_count\n",
        "\n",
        "            training_history.append(epoch_losses)\n",
        "\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}] - \"\n",
        "                  f\"Recon Loss: {epoch_losses['reconstruction_loss']:.4f}, \"\n",
        "                  f\"Gen Loss: {epoch_losses['generator_loss']:.4f}, \"\n",
        "                  f\"Disc Loss: {epoch_losses['discriminator_loss']:.4f}\")\n",
        "\n",
        "        return training_history\n",
        "\n",
        "    def encode(self, x):\n",
        "        self.encoder.eval()\n",
        "        with torch.no_grad():\n",
        "            x = x.to(self.device)\n",
        "            z = self.encoder(x)\n",
        "        return z\n",
        "\n",
        "    def decode(self, z):\n",
        "        self.decoder.eval()\n",
        "        with torch.no_grad():\n",
        "            z = z.to(self.device)\n",
        "            x_reconstructed = self.decoder(z)\n",
        "        return x_reconstructed\n",
        "\n",
        "    def reconstruct(self, x):\n",
        "        self.encoder.eval()\n",
        "        self.decoder.eval()\n",
        "        with torch.no_grad():\n",
        "            x = x.to(self.device)\n",
        "            z = self.encoder(x)\n",
        "            x_reconstructed = self.decoder(z)\n",
        "        return x_reconstructed\n",
        "\n",
        "    def save_model(self, path):\n",
        "        torch.save({\n",
        "            'encoder_state_dict': self.encoder.state_dict(),\n",
        "            'decoder_state_dict': self.decoder.state_dict(),\n",
        "            'discriminator_state_dict': self.discriminator.state_dict()\n",
        "        }, path)\n",
        "\n",
        "    def load_model(self, path):\n",
        "        checkpoint = torch.load(path)\n",
        "        self.encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
        "        self.decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
        "        self.discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n"
      ],
      "metadata": {
        "id": "5T_tpplCDjgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df = pd.read_parquet(os.path.join(root, 'movies_embeddings.parquet'), engine='pyarrow')\n",
        "songs_df = pd.read_parquet(os.path.join(root, 'song_embeddings.parquet'), engine='pyarrow')\n"
      ],
      "metadata": {
        "id": "PXhrcdVB0JaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.head()"
      ],
      "metadata": {
        "id": "dcsP1dpu0MrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "songs_df.head()"
      ],
      "metadata": {
        "id": "GIGtX8Yw0Ojq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#'label' column to movies_df with value 1\n",
        "movies_df['label'] = 1\n",
        "\n",
        "# 'label' column to songs_df with value 0\n",
        "songs_df['label'] = 0\n",
        "\n",
        "# Keep only the 'embedding' and 'label' columns\n",
        "movies_df = movies_df[['embedding', 'label']]\n",
        "songs_df = songs_df[['embedding', 'label']]\n"
      ],
      "metadata": {
        "id": "fKB-i-5W0PRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vertically stack (concatenate) the two DataFrames\n",
        "combined_data = pd.concat([movies_data, songs_data], axis=0, ignore_index=True)\n",
        "\n",
        "# Shuffle the combined DataFrame\n",
        "combined_data = combined_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Extract combined embeddings and labels\n",
        "# Assuming that the embedding column stores a list of numbers for each row.\n",
        "combined_embeddings = np.array(combined_data['embedding'].tolist())\n",
        "combined_labels = np.array(combined_data['label'].tolist())\n",
        "\n",
        "combined_embeddings.shape, combined_labels.shape"
      ],
      "metadata": {
        "id": "lSbudBTt1ui2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_embeddings = torch.tensor(combined_embeddings, dtype=torch.float32)\n",
        "combined_labels = torch.tensor(combined_labels, dtype=torch.float32)\n",
        "\n",
        "combined_dataset = TensorDataset(combined_embeddings, combined_labels)\n",
        "combined_dataloader = DataLoader(combined_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "8DwNRXzD139q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}