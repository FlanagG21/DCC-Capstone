{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11036461,"sourceType":"datasetVersion","datasetId":6874159},{"sourceId":346429,"sourceType":"modelInstanceVersion","modelInstanceId":289444,"modelId":310182}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install faiss-cpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:07:01.577273Z","iopub.execute_input":"2025-04-20T22:07:01.577489Z","iopub.status.idle":"2025-04-20T22:07:08.351650Z","shell.execute_reply.started":"2025-04-20T22:07:01.577469Z","shell.execute_reply":"2025-04-20T22:07:08.350362Z"}},"outputs":[{"name":"stdout","text":"Collecting faiss-cpu\n  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nDownloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.10.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport seaborn as sns\nimport random\nimport numpy as np\nimport pandas as pd\nfrom sklearn.neighbors import NearestNeighbors\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:07:32.047819Z","iopub.execute_input":"2025-04-20T22:07:32.048156Z","iopub.status.idle":"2025-04-20T22:07:32.054082Z","shell.execute_reply.started":"2025-04-20T22:07:32.048121Z","shell.execute_reply":"2025-04-20T22:07:32.053082Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_dim=768, latent_dim=256):\n        super(Encoder, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 512)\n        self.bn1 = nn.BatchNorm1d(512)\n\n        self.fc2 = nn.Linear(512, 384)\n        self.bn2 = nn.BatchNorm1d(384)\n\n        self.fc3 = nn.Linear(384, latent_dim)\n\n    def forward(self, x):\n        h = F.leaky_relu(self.bn1(self.fc1(x)), 0.2)\n        h = F.leaky_relu(self.bn2(self.fc2(h)), 0.2)\n        latent = self.fc3(h)\n        return latent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:37:55.574033Z","iopub.execute_input":"2025-04-20T14:37:55.574369Z","iopub.status.idle":"2025-04-20T14:37:55.579502Z","shell.execute_reply.started":"2025-04-20T14:37:55.574350Z","shell.execute_reply":"2025-04-20T14:37:55.578837Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, latent_dim=256, output_dim=768):\n        super(Decoder, self).__init__()\n        self.fc1 = nn.Linear(latent_dim, 384)\n        self.bn1 = nn.BatchNorm1d(384)\n\n        self.fc2 = nn.Linear(384, 512)\n        self.bn2 = nn.BatchNorm1d(512)\n\n        self.fc3 = nn.Linear(512, output_dim)\n\n    def forward(self, z):\n        h = F.leaky_relu(self.bn1(self.fc1(z)), 0.2)\n        h = F.leaky_relu(self.bn2(self.fc2(h)), 0.2)\n        reconstructed = torch.sigmoid(self.fc3(h))\n        return reconstructed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:37:55.580372Z","iopub.execute_input":"2025-04-20T14:37:55.580706Z","iopub.status.idle":"2025-04-20T14:37:55.608322Z","shell.execute_reply.started":"2025-04-20T14:37:55.580661Z","shell.execute_reply":"2025-04-20T14:37:55.607662Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, latent_dim=256):\n        super(Discriminator, self).__init__()\n        self.fc1 = nn.Linear(latent_dim, 256)\n        self.bn1 = nn.BatchNorm1d(256)\n\n        self.fc2 = nn.Linear(256, 128)\n        self.bn2 = nn.BatchNorm1d(128)\n\n        self.fc3 = nn.Linear(128, 1)\n\n    def forward(self, z):\n        h = F.leaky_relu(self.bn1(self.fc1(z)), 0.2)\n        h = F.leaky_relu(self.bn2(self.fc2(h)), 0.2)\n        logits = self.fc3(h)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:37:55.609056Z","iopub.execute_input":"2025-04-20T14:37:55.609307Z","iopub.status.idle":"2025-04-20T14:37:55.627061Z","shell.execute_reply.started":"2025-04-20T14:37:55.609284Z","shell.execute_reply":"2025-04-20T14:37:55.626409Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class AdversarialAutoencoder:\n    def __init__(self, input_dim=768, latent_dim=256, device='cuda' if torch.cuda.is_available() else 'cpu'):\n        self.input_dim = input_dim\n        self.latent_dim = latent_dim\n        self.device = device\n\n        # Initialize networks\n        self.encoder = Encoder(input_dim, latent_dim).to(device)\n        self.decoder = Decoder(latent_dim, input_dim).to(device)\n        self.discriminator = Discriminator(latent_dim).to(device)\n\n        # Initialize optimizers\n        self.encoder_optimizer = optim.Adam(self.encoder.parameters(), lr=0.001)\n        self.decoder_optimizer = optim.Adam(self.decoder.parameters(), lr=0.001)\n        self.discriminator_optimizer = optim.Adam(self.discriminator.parameters(), lr=0.0001)\n\n        # Loss functions\n        self.reconstruction_loss = nn.MSELoss()\n        self.adversarial_loss = nn.BCEWithLogitsLoss()\n\n    def train_step(self, x_batch):\n        batch_size = x_batch.size(0)\n        x_batch = x_batch.to(self.device)\n\n        # Target tensors\n        real_target = torch.ones(batch_size, 1).to(self.device)\n        fake_target = torch.zeros(batch_size, 1).to(self.device)\n\n        # Train Autoencoder\n        self.encoder_optimizer.zero_grad()\n        self.decoder_optimizer.zero_grad()\n\n        # Encode and decode the input\n        z = self.encoder(x_batch)\n        x_reconstructed = self.decoder(z)\n\n        # Compute reconstruction loss\n        recon_loss = self.reconstruction_loss(x_reconstructed, x_batch)\n\n        # Compute adversarial loss for the generator (encoder)\n        gen_loss = self.adversarial_loss(self.discriminator(z), real_target)\n\n        # Total autoencoder loss\n        ae_loss = recon_loss + gen_loss\n\n        # Backpropagate and update parameters\n        ae_loss.backward()\n        self.encoder_optimizer.step()\n        self.decoder_optimizer.step()\n\n        # Train Discriminator\n        self.discriminator_optimizer.zero_grad()\n\n        # Generate latent vectors from the prior distribution (Gaussian in this case)\n        z_prior = torch.randn(batch_size, self.latent_dim).to(self.device)\n\n        # Get encoded samples\n        z_encoded = self.encoder(x_batch).detach()  # Detach to avoid training the encoder again\n\n        # Compute discriminator loss\n        real_loss = self.adversarial_loss(self.discriminator(z_prior), real_target)\n        fake_loss = self.adversarial_loss(self.discriminator(z_encoded), fake_target)\n        d_loss = (real_loss + fake_loss) / 2\n\n        # Backpropagate and update parameters\n        d_loss.backward()\n        self.discriminator_optimizer.step()\n\n        return {\n            'reconstruction_loss': recon_loss.item(),\n            'generator_loss': gen_loss.item(),\n            'discriminator_loss': d_loss.item()\n        }\n\n    def train(self, data_loader, epochs=100):\n        self.encoder.train()\n        self.decoder.train()\n        self.discriminator.train()\n\n        training_history = []\n\n        for epoch in range(epochs):\n            epoch_losses = {'reconstruction_loss': 0, 'generator_loss': 0, 'discriminator_loss': 0}\n            batch_count = 0\n\n            for batch_idx, (x_batch, _) in enumerate(data_loader):\n                step_losses = self.train_step(x_batch)\n\n                for key in epoch_losses:\n                    epoch_losses[key] += step_losses[key]\n                batch_count += 1\n\n            # Calculate average losses for the epoch\n            for key in epoch_losses:\n                epoch_losses[key] /= batch_count\n\n            training_history.append(epoch_losses)\n\n            print(f\"Epoch [{epoch+1}/{epochs}] - \"\n                  f\"Recon Loss: {epoch_losses['reconstruction_loss']:.4f}, \"\n                  f\"Gen Loss: {epoch_losses['generator_loss']:.4f}, \"\n                  f\"Disc Loss: {epoch_losses['discriminator_loss']:.4f}\")\n\n        return training_history\n\n    def encode(self, x):\n        self.encoder.eval()\n        with torch.no_grad():\n            x = x.to(self.device)\n            z = self.encoder(x)\n        return z\n\n    def decode(self, z):\n        self.decoder.eval()\n        with torch.no_grad():\n            z = z.to(self.device)\n            x_reconstructed = self.decoder(z)\n        return x_reconstructed\n\n    def reconstruct(self, x):\n        self.encoder.eval()\n        self.decoder.eval()\n        with torch.no_grad():\n            x = x.to(self.device)\n            z = self.encoder(x)\n            x_reconstructed = self.decoder(z)\n        return x_reconstructed\n\n    def save_model(self, path):\n        torch.save({\n            'encoder_state_dict': self.encoder.state_dict(),\n            'decoder_state_dict': self.decoder.state_dict(),\n            'discriminator_state_dict': self.discriminator.state_dict()\n        }, path)\n\n    def load_model(self, path):\n        checkpoint = torch.load(path,  weights_only=True)\n        self.encoder.load_state_dict(checkpoint['encoder_state_dict'])\n        self.decoder.load_state_dict(checkpoint['decoder_state_dict'])\n        self.discriminator.load_state_dict(checkpoint['discriminator_state_dict'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:37:55.627744Z","iopub.execute_input":"2025-04-20T14:37:55.627995Z","iopub.status.idle":"2025-04-20T14:37:55.705055Z","shell.execute_reply.started":"2025-04-20T14:37:55.627977Z","shell.execute_reply":"2025-04-20T14:37:55.704280Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(torch.cuda.is_available())\nprint(torch.cuda.current_device())\nprint(torch.cuda.get_device_name(0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:37:55.705915Z","iopub.execute_input":"2025-04-20T14:37:55.706124Z","iopub.status.idle":"2025-04-20T14:37:55.747728Z","shell.execute_reply.started":"2025-04-20T14:37:55.706107Z","shell.execute_reply":"2025-04-20T14:37:55.747170Z"}},"outputs":[{"name":"stdout","text":"True\n0\nTesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/input/autoencoder/pytorch/default/1/models/best_aae_model.pt')\nprint(checkpoint.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:37:55.748302Z","iopub.execute_input":"2025-04-20T14:37:55.748477Z","iopub.status.idle":"2025-04-20T14:37:56.028916Z","shell.execute_reply.started":"2025-04-20T14:37:55.748462Z","shell.execute_reply":"2025-04-20T14:37:56.028256Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/1911931023.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load('/kaggle/input/autoencoder/pytorch/default/1/models/best_aae_model.pt')\n","output_type":"stream"},{"name":"stdout","text":"dict_keys(['encoder_state_dict', 'decoder_state_dict', 'discriminator_state_dict'])\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"bestModel = AdversarialAutoencoder()\nbestModel.load_model(\"/kaggle/input/autoencoder/pytorch/default/1/models/best_aae_model.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:37:56.031189Z","iopub.execute_input":"2025-04-20T14:37:56.031404Z","iopub.status.idle":"2025-04-20T14:37:58.378998Z","shell.execute_reply.started":"2025-04-20T14:37:56.031388Z","shell.execute_reply":"2025-04-20T14:37:58.378433Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Basic Recommendation on whole data","metadata":{}},{"cell_type":"code","source":"movies_df = pd.read_parquet(\"/kaggle/input/recommendation-embeddings-inputs/movies_embeddings.parquet\")\nsongs_df = pd.read_parquet(\"/kaggle/input/recommendation-embeddings-inputs/song_embeddings.parquet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:07:38.615038Z","iopub.execute_input":"2025-04-20T22:07:38.615858Z","iopub.status.idle":"2025-04-20T22:09:35.729786Z","shell.execute_reply.started":"2025-04-20T22:07:38.615830Z","shell.execute_reply":"2025-04-20T22:09:35.728130Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"movies_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:09:35.732774Z","iopub.execute_input":"2025-04-20T22:09:35.733740Z","iopub.status.idle":"2025-04-20T22:09:35.775040Z","shell.execute_reply.started":"2025-04-20T22:09:35.733695Z","shell.execute_reply":"2025-04-20T22:09:35.774192Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       id            title                                           overview  \\\n0   27205        Inception  Cobb a skilled thief who commits corporate esp...   \n1  157336     Interstellar  The adventures of a group of explorers who mak...   \n2     155  The Dark Knight  Batman raises the stakes in his war on crime W...   \n3   19995           Avatar  In the 22nd century a paraplegic Marine is dis...   \n4   24428     The Avengers  When an unexpected enemy emerges and threatens...   \n\n                                        genres  \\\n0           Action, Science Fiction, Adventure   \n1            Adventure, Drama, Science Fiction   \n2               Drama, Action, Crime, Thriller   \n3  Action, Adventure, Fantasy, Science Fiction   \n4           Science Fiction, Action, Adventure   \n\n                                           embedding  \n0  [0.01589059643447399, 0.11273891478776932, -0....  \n1  [0.037922028452157974, -0.005655079614371061, ...  \n2  [0.011266704648733139, 0.032755907624959946, -...  \n3  [0.01744804158806801, 0.03436880186200142, 0.0...  \n4  [0.027801260352134705, -0.019952325150370598, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>overview</th>\n      <th>genres</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>27205</td>\n      <td>Inception</td>\n      <td>Cobb a skilled thief who commits corporate esp...</td>\n      <td>Action, Science Fiction, Adventure</td>\n      <td>[0.01589059643447399, 0.11273891478776932, -0....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>157336</td>\n      <td>Interstellar</td>\n      <td>The adventures of a group of explorers who mak...</td>\n      <td>Adventure, Drama, Science Fiction</td>\n      <td>[0.037922028452157974, -0.005655079614371061, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>155</td>\n      <td>The Dark Knight</td>\n      <td>Batman raises the stakes in his war on crime W...</td>\n      <td>Drama, Action, Crime, Thriller</td>\n      <td>[0.011266704648733139, 0.032755907624959946, -...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19995</td>\n      <td>Avatar</td>\n      <td>In the 22nd century a paraplegic Marine is dis...</td>\n      <td>Action, Adventure, Fantasy, Science Fiction</td>\n      <td>[0.01744804158806801, 0.03436880186200142, 0.0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24428</td>\n      <td>The Avengers</td>\n      <td>When an unexpected enemy emerges and threatens...</td>\n      <td>Science Fiction, Action, Adventure</td>\n      <td>[0.027801260352134705, -0.019952325150370598, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"songs_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:09:35.775943Z","iopub.execute_input":"2025-04-20T22:09:35.776197Z","iopub.status.idle":"2025-04-20T22:09:35.789980Z","shell.execute_reply.started":"2025-04-20T22:09:35.776175Z","shell.execute_reply":"2025-04-20T22:09:35.789226Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                  title      tag  \\\n0  Poor Poor Pitiful Me  country   \n1          Cuckoos Nest  country   \n2         Wedding Bells  country   \n3  Could Have Fooled Me  country   \n4         Shot of Glory  country   \n\n                                              lyrics  \\\n0  Well I lay my head on the railroad track\\nWait...   \n1  There is a thorn bush\\nIn Outcolia\\nThere is a...   \n2  I have the invitation that your sent me\\nYou w...   \n3  Im fading like the taillights\\nOf a car that y...   \n4  Its finally payday\\nMeeting the boys at my pla...   \n\n                                           embedding  \n0  [0.029062896966934204, 0.08223594725131989, -0...  \n1  [0.0009067401406355202, -0.09515126794576645, ...  \n2  [0.04617173597216606, 0.013956493698060513, -0...  \n3  [0.015817370265722275, -0.0025993576273322105,...  \n4  [-0.011555955745279789, 0.0511910654604435, 0....  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>tag</th>\n      <th>lyrics</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Poor Poor Pitiful Me</td>\n      <td>country</td>\n      <td>Well I lay my head on the railroad track\\nWait...</td>\n      <td>[0.029062896966934204, 0.08223594725131989, -0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cuckoos Nest</td>\n      <td>country</td>\n      <td>There is a thorn bush\\nIn Outcolia\\nThere is a...</td>\n      <td>[0.0009067401406355202, -0.09515126794576645, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Wedding Bells</td>\n      <td>country</td>\n      <td>I have the invitation that your sent me\\nYou w...</td>\n      <td>[0.04617173597216606, 0.013956493698060513, -0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Could Have Fooled Me</td>\n      <td>country</td>\n      <td>Im fading like the taillights\\nOf a car that y...</td>\n      <td>[0.015817370265722275, -0.0025993576273322105,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Shot of Glory</td>\n      <td>country</td>\n      <td>Its finally payday\\nMeeting the boys at my pla...</td>\n      <td>[-0.011555955745279789, 0.0511910654604435, 0....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"movie_emb = np.vstack(movies_df['embedding'].values)\nsong_emb  = np.vstack(songs_df['embedding'].values)\n\nnn = NearestNeighbors(n_neighbors=5, metric='cosine', algorithm='brute')\nnn.fit(movie_emb)\n\ntitles = movies_df['title'].tolist()\nrecs   = []\n\nbatch_size = 500\nfor start in range(0, song_emb.shape[0], batch_size):\n    end   = min(start + batch_size, song_emb.shape[0])\n    batch = song_emb[start:end]\n    dist, idx = nn.kneighbors(batch)\n\n    for i, (neigh_idxs, neigh_dists) in enumerate(zip(idx, dist)):\n        song = songs_df.iloc[start + i]\n        row = {\n            'song_title': song['title'],\n            'tag':        song['tag'],\n            'lyrics':     song['lyrics'],\n        }\n        for rank, (m_idx, d) in enumerate(zip(neigh_idxs, neigh_dists), start=1):\n            row[f'best{rank}_title'] = titles[m_idx]\n            row[f'best{rank}_score'] = float(1.0 - d)\n        recs.append(row)\n\nrec_df = pd.DataFrame(recs)\nrec_df.to_csv(\"recommendation_with_scores.csv\",index=False)\nrec_df.head(), rec_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T22:09:35.791418Z","iopub.execute_input":"2025-04-20T22:09:35.791730Z","iopub.status.idle":"2025-04-21T04:29:48.510033Z","shell.execute_reply.started":"2025-04-20T22:09:35.791702Z","shell.execute_reply":"2025-04-21T04:29:48.506534Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(             song_title      tag  \\\n 0  Poor Poor Pitiful Me  country   \n 1          Cuckoos Nest  country   \n 2         Wedding Bells  country   \n 3  Could Have Fooled Me  country   \n 4         Shot of Glory  country   \n \n                                               lyrics  \\\n 0  Well I lay my head on the railroad track\\nWait...   \n 1  There is a thorn bush\\nIn Outcolia\\nThere is a...   \n 2  I have the invitation that your sent me\\nYou w...   \n 3  Im fading like the taillights\\nOf a car that y...   \n 4  Its finally payday\\nMeeting the boys at my pla...   \n \n                                     best1_title  best1_score  \\\n 0                               Faceless Things     0.526864   \n 1                                  Soul Catcher     0.538646   \n 2                                  Tainted Love     0.588257   \n 3                                  Tainted Love     0.720001   \n 4  The White Stripes: Under Nova Scotian Lights     0.592151   \n \n                           best2_title  best2_score  \\\n 0            How I Fucked Your Mother     0.523354   \n 1                            Lácrimas     0.530201   \n 2                          Surrender!     0.549636   \n 3                            愛という名の銃弾     0.613563   \n 4  Buddy Guy Live From Red Rocks 2013     0.591826   \n \n                                       best3_title  best3_score  \\\n 0                                  Cuck 'Em All 2     0.504174   \n 1                         Bathwell in Clerkentime     0.514016   \n 2                  A Love Letter to All Those Men     0.543320   \n 3                                        愛という名の銃弾     0.613563   \n 4  Queens of the Stone Age : Itunes Festival 2013     0.566841   \n \n                                  best4_title  best4_score  \\\n 0                            Toy Box Killers     0.500357   \n 1                           Coo-Coo Bird Dog     0.505178   \n 2                                   Thirteen     0.489043   \n 3                                 Surrender!     0.612859   \n 4  Nashville Pussy: Keep On Fuckin' in Paris     0.562291   \n \n             best5_title  best5_score  \n 0          Trew Calling     0.499681  \n 1              Dominion     0.502486  \n 2    Black Tie Optional     0.484910  \n 3  Misery Loves Company     0.585945  \n 4   Great Balls of Fire     0.561825  ,\n (519948, 13))"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"rec_df.to_csv(\"recommendation_with_scores.csv\",index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:01:06.441080Z","iopub.execute_input":"2025-04-21T05:01:06.446489Z","iopub.status.idle":"2025-04-21T05:01:50.036908Z","shell.execute_reply.started":"2025-04-21T05:01:06.446369Z","shell.execute_reply":"2025-04-21T05:01:50.034970Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Autoencoder Recommendation for whole data","metadata":{}},{"cell_type":"code","source":"song_embeddings = np.array(songs_df['embedding'].tolist())\nsong_embeddings = torch.tensor(song_embeddings, dtype=torch.float32)\nmovie_embeddings = np.array(movies_df['embedding'].tolist())\nmovie_embeddings = torch.tensor(movie_embeddings, dtype=torch.float32)\n\nsongs_df[\"embedding\"] = [embedding.tolist() for embedding in bestModel.encode(song_embeddings).cpu().detach().numpy()]\nmovies_df[\"embedding\"] = [embedding.tolist() for embedding in bestModel.encode(movie_embeddings).cpu().detach().numpy()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:39:39.951938Z","iopub.execute_input":"2025-04-20T14:39:39.952290Z","iopub.status.idle":"2025-04-20T14:40:09.401593Z","shell.execute_reply.started":"2025-04-20T14:39:39.952268Z","shell.execute_reply":"2025-04-20T14:40:09.401036Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"del song_embeddings\ndel movie_embeddings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:40:09.402343Z","iopub.execute_input":"2025-04-20T14:40:09.402602Z","iopub.status.idle":"2025-04-20T14:40:09.716932Z","shell.execute_reply.started":"2025-04-20T14:40:09.402580Z","shell.execute_reply":"2025-04-20T14:40:09.716153Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.neighbors import NearestNeighbors\n\nmovie_emb = np.vstack(movies_df['embedding'].values)\nsong_emb  = np.vstack(songs_df['embedding'].values)\n\nnn = NearestNeighbors(n_neighbors=5, metric='cosine', algorithm='brute')\nnn.fit(movie_emb)\n\ntitles = movies_df['title'].tolist()\nrecs   = []\n\nbatch_size = 500\nfor start in range(0, song_emb.shape[0], batch_size):\n    end   = min(start + batch_size, song_emb.shape[0])\n    batch = song_emb[start:end]\n    dist, idx = nn.kneighbors(batch)\n\n    for i, (neigh_idxs, neigh_dists) in enumerate(zip(idx, dist)):\n        song = songs_df.iloc[start + i]\n        row = {\n            'song_title': song['title'],\n            'tag':        song['tag'],\n            'lyrics':     song['lyrics'],\n        }\n        for rank, (m_idx, d) in enumerate(zip(neigh_idxs, neigh_dists), start=1):\n            row[f'best{rank}_title'] = titles[m_idx]\n            row[f'best{rank}_score'] = float(1.0 - d)\n        recs.append(row)\n\nrec_df = pd.DataFrame(recs)\nrec_df.to_csv(\"autoencoder_recommendation_with_scores.csv\",index=False)\nrec_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T14:47:55.698752Z","iopub.execute_input":"2025-04-20T14:47:55.699046Z","iopub.status.idle":"2025-04-20T17:12:37.716318Z","shell.execute_reply.started":"2025-04-20T14:47:55.699025Z","shell.execute_reply":"2025-04-20T17:12:37.715252Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/1781028084.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mrec_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mrec_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/data/recommendation_with_scores.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mrec_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3965\u001b[0m         )\n\u001b[1;32m   3966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3967\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3968\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         )\n\u001b[0;32m-> 1014\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \"\"\"\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/mnt/data'"],"ename":"OSError","evalue":"Cannot save file into a non-existent directory: '/mnt/data'","output_type":"error"}],"execution_count":23},{"cell_type":"code","source":"rec_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:35:41.049941Z","iopub.execute_input":"2025-04-20T17:35:41.050578Z","iopub.status.idle":"2025-04-20T17:35:41.056958Z","shell.execute_reply.started":"2025-04-20T17:35:41.050528Z","shell.execute_reply":"2025-04-20T17:35:41.056229Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"(519948, 13)"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}